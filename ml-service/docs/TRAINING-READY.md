# üéØ ML Training Ready - All Issues Fixed

## üéâ Status: Ready to Train (Build in Progress)

All 4 critical issues have been resolved. Once the Docker build completes, ML training will work correctly.

---

## üìã Issues Fixed

### ‚úÖ Issue 1: PostgreSQL Connection
**Problem**: ML service couldn't connect to PostgreSQL  
**Error**: `connection to server at "localhost" (127.0.0.1), port 5432 failed`  
**Fixed**: Updated `docker-compose.yml` to use `DB_HOST=postgres` and join `Iotistic-net` network

### ‚úÖ Issue 2: SQL Syntax Error
**Problem**: INTERVAL parameter substitution broken  
**Error**: `syntax error at or near "168" ... INTERVAL ''168' hours`  
**Fixed**: Changed from `INTERVAL '%s hours'` with params to f-string `INTERVAL '{hours} hours'`

### ‚úÖ Issue 3: Field Name Mismatch
**Problem**: Query searched for wrong field names  
**Error**: `Fetched 0 multi-metric data points` (query returned no data)  
**Root Cause**: 
- Query searched for `memoryUsed`/`diskUsed` but data has `memoryUsage`/`diskUsage`
- Query searched for network fields that don't exist
**Fixed**: Updated SQL query in `services/data_fetcher.py` to match actual data structure

### ‚úÖ Issue 4: Hardcoded Features
**Problem**: Router required features that don't exist  
**Error**: `Missing features in data: ['network_total']`  
**Fixed**: Implemented dynamic feature selection in `routers/anomalies.py`

---

## üìä Data Structure (Final)

**Your Device Shadow History** (220 records):
```json
{
  "system": {
    "cpuUsage": 27.4,
    "memoryUsage": 13534,
    "memoryTotal": 16320,
    "diskUsage": 474,
    "diskTotal": 476,
    "temperature": null
  },
  "health": {
    "uptime": 6542
  }
}
```

**ML Features Used**:
- ‚úÖ `cpu_usage` - CPU usage percentage
- ‚úÖ `memory_usage_percent` - Calculated: (memoryUsage / memoryTotal) * 100
- ‚úÖ `disk_usage_percent` - Calculated: (diskUsage / diskTotal) * 100
- ‚úÖ `uptime` - System uptime in seconds
- ‚ö†Ô∏è `temperature` - Available but currently null

**Total Training Samples**: 220 records from 2025-10-19 00:27 to 02:16 (~2 hours)

---

## üöÄ Quick Start (Once Build Completes)

### Step 1: Check Service is Running
```powershell
# Should return 200 OK
curl http://localhost:5000/health
```

### Step 2: Run Complete Test
```powershell
cd ml-service
.\test-training.ps1
```

This will:
1. ‚úÖ Check ML service health
2. üß† Train Isolation Forest model (220 samples, 4 features)
3. üîç Detect anomalies in last 24 hours
4. üìä Show results with anomaly details

### Step 3: Manual Training (Alternative)
```powershell
# Device UUID
$uuid = "46b68204-9806-43c5-8d19-18b1f53e3b8a"

# Train model (7 days of data)
curl -X POST "http://localhost:5000/ml/anomalies/train/$uuid`?hours=168"

# Expected response:
# {
#   "message": "Model trained successfully",
#   "device_uuid": "46b68204-9806-43c5-8d19-18b1f53e3b8a",
#   "training_samples": 220,
#   "features": ["cpu_usage", "memory_usage_percent", "disk_usage_percent", "uptime"],
#   "contamination": 0.01
# }

# Detect anomalies (last 24 hours)
curl "http://localhost:5000/ml/anomalies/detect/$uuid`?hours=24"
```

---

## üîß Working Configuration

### Docker Compose
```yaml
services:
  ml-service:
    environment:
      DB_HOST: ${DB_HOST:-postgres}  # ‚Üê Changed from localhost
      DB_NAME: ${DB_NAME:-digital_twin}
      DB_USER: ${DB_USER:-myuser}
      DB_PASSWORD: ${DB_PASSWORD:-mypassword}
    networks:
      - Iotistic-net  # ‚Üê Changed from ml-network
    depends_on:
      - postgres

networks:
  Iotistic-net:
    external: true  # ‚Üê Uses existing Digital Twin network
```

### SQL Query (data_fetcher.py)
```python
query = f"""
    SELECT 
        timestamp,
        (reported_state#>>'{{system,cpuUsage}}')::float as cpu_usage,
        (reported_state#>>'{{system,memoryUsage}}')::float as memory_used,
        (reported_state#>>'{{system,memoryTotal}}')::float as memory_total,
        (reported_state#>>'{{system,diskUsage}}')::float as disk_used,
        (reported_state#>>'{{system,diskTotal}}')::float as disk_total,
        (reported_state#>>'{{health,uptime}}')::float as uptime,
        (reported_state#>>'{{system,temperature}}')::float as temperature
    FROM device_shadow_history
    WHERE device_uuid = %s
        AND timestamp >= NOW() - INTERVAL '{hours} hours'
        AND reported_state ? 'system'
    ORDER BY timestamp ASC
"""
```

### Dynamic Features (anomalies.py)
```python
# Only use features that exist in data
all_possible_features = [
    'cpu_usage', 
    'memory_usage_percent', 
    'disk_usage_percent', 
    'uptime', 
    'temperature'
]
features = [
    f for f in all_possible_features 
    if f in df.columns and df[f].notna().sum() > 0
]

# Expected result (temperature is null):
# features = ['cpu_usage', 'memory_usage_percent', 'disk_usage_percent', 'uptime']
```

---

## üìà Expected Training Results

**Model**: Isolation Forest (unsupervised anomaly detection)  
**Training Samples**: ~220 device shadow records  
**Features**: 4 (cpu, memory%, disk%, uptime)  
**Contamination**: 0.01 (expect 1% anomalies)

**Success Indicators**:
- ‚úÖ Training completes without errors
- ‚úÖ Model file saved to `models/isolation_forest_<device_uuid>.pkl`
- ‚úÖ Anomaly detection returns results
- ‚úÖ Anomaly scores between -1 (anomalous) and 1 (normal)

---

## üîó Integration with Digital Twin

Once training works, integrate ML predictions with your entity-relationship graph:

### Step 1: Link Device to Entity
```powershell
# Create entity for device
$entity = Invoke-RestMethod -Uri "http://localhost:4002/api/v1/entities" `
    -Method POST -ContentType "application/json" `
    -Body '{
        "entity_type": "device",
        "name": "BME688 Sensor",
        "metadata": {"device_type": "environmental_sensor"}
    }'

# Link to device shadow
Invoke-RestMethod -Uri "http://localhost:4002/api/v1/entities/$($entity.id)/device" `
    -Method POST -ContentType "application/json" `
    -Body "{`"device_uuid`": `"46b68204-9806-43c5-8d19-18b1f53e3b8a`"}"
```

### Step 2: Store ML Predictions
```powershell
# After anomaly detection
Invoke-RestMethod -Uri "http://localhost:4002/api/v1/entities/$($entity.id)/properties" `
    -Method POST -ContentType "application/json" `
    -Body '{
        "property_name": "ml_anomaly_detection",
        "property_value": {
            "anomaly_score": 0.85,
            "is_anomaly": true,
            "timestamp": "2025-10-19T03:00:00Z",
            "features_analyzed": ["cpu_usage", "memory_usage_percent", "disk_usage_percent", "uptime"]
        }
    }'
```

### Step 3: Use Impact Analysis
```powershell
# If anomaly detected, analyze impact on related entities
Invoke-RestMethod -Uri "http://localhost:4002/api/v1/graph/impact" `
    -Method POST -ContentType "application/json" `
    -Body "{
        `"affected_entity_id`": `"$($entity.id)`",
        `"impact_scenario`": `"device_failure`"
    }"
```

See **`docs/ML-DIGITAL-TWIN-INTEGRATION.md`** for complete integration patterns.

---

## üìö Documentation

- **QUICK-START-TRAINING.md** - Step-by-step training guide
- **SETUP-FIXED.md** - Complete setup documentation
- **ISSUES-RESOLVED.md** - Summary of all fixes applied
- **diagnose-data.ps1** - Database diagnostics script
- **test-training.ps1** - Automated training test (THIS IS THE ONE TO RUN!)
- **docs/ML-DIGITAL-TWIN-INTEGRATION.md** - 600+ lines of integration examples

---

## üîç Troubleshooting

### Check Build Status
```powershell
cd ml-service
docker-compose logs -f ml-service
```

### If Training Fails
```powershell
# Verify data exists
.\diagnose-data.ps1

# Check logs
docker-compose logs ml-service

# Restart service
docker-compose restart ml-service
```

### Common Issues
- **Connection refused**: Check `docker-compose ps` - is postgres running?
- **No data found**: Run `diagnose-data.ps1` to verify shadow history records
- **Missing features**: Check `docker-compose logs ml-service` for feature list
- **Model not saving**: Check volume mount in docker-compose.yml

---

## üéØ Next Steps After Training

1. **Set up automated retraining** - Retrain every 24 hours with new data
2. **Create ML dashboard** - Visualize anomalies and predictions
3. **Integrate with alerting** - Send notifications on anomalies
4. **Expand to LSTM forecasting** - Predict future metric values
5. **Connect to fire evacuation** - Use ML to optimize evacuation routes based on predicted failures

---

## ‚è∞ Build Status

**Current**: Docker build in progress (installing TensorFlow, xgboost, etc.)  
**ETA**: ~2-3 more minutes  
**Steps**: 5/7 complete (installing packages), then copy files and create directories

Once you see "ml-service-1 Started" in docker-compose logs, run:
```powershell
.\test-training.ps1
```

üéâ **You're ready to train!** All code fixes are in place. Just waiting for Docker build to complete.
